# Python 线程与进程

现在的 PC 都是多核的，使用多线程能充分利用 CPU 来提供程序的执行效率

## 概念 
### 线程
* 线程是一个基本的 CPU 执行单元。它必须依托于进程存活。一个线程是一个execution context（执行上下文），即一个 CPU 执行时所需要的一串指令。

### 线程的类型
线程的因作用可以划分为不同的类型。大致可分为：
* 主线程
* 子线程
* 守护线程（后台线程）
* 前台线程


### 进程
* 进程是指一个程序在给定数据集合上的一次执行过程，是系统进行资源分配和运行调用的独立单位。可以简单地理解为操作系统中正在执行的程序。也就说，每个应用程序都有一个自己的进程。
* 每一个进程启动时都会最先产生一个线程，即主线程。然后主线程会再创建其他的子线程。

### 区别
* 线程必须在某个进行中执行。
* 一个进程可包含多个线程，其中有且只有一个主线程。
* 多线程共享同个地址空间、打开的文件以及其他资源。
* 多进程共享物理内存、磁盘、打印机以及其他资源。


## 多线程

### GIL
GIL 的全称是 Global Interpreter Lock(全局解释器锁)，来源是 Python 设计之初的考虑，为了数据安全所做的决定。某个线程想要执行，必须先拿到 GIL，我们可以把 GIL 看作是“通行证”，并且在一个 Python 进程中，GIL 只有一个。拿不到通行证的线程，就不允许进入 CPU 执行。

而目前 Python 的解释器有多种，例如：

    CPython：CPython 是用C语言实现的 Python 解释器。 作为官方实现，它是最广泛使用的 Python 解释器。

    PyPy：PyPy 是用RPython实现的解释器。RPython 是 Python 的子集， 具有静态类型。这个解释器的特点是即时编译，支持多重后端（C, CLI, JVM）。PyPy 旨在提高性能，同时保持最大兼容性（参考 CPython 的实现）。

    Jython：Jython 是一个将 Python 代码编译成 Java 字节码的实现，运行在JVM (Java Virtual Machine) 上。另外，它可以像是用 Python 模块一样，导入 并使用任何Java类。

    IronPython：IronPython 是一个针对 .NET 框架的 Python 实现。它 可以用 Python 和 .NET framewor k的库，也能将 Python 代码暴露给 .NET 框架中的其他语言。

GIL 只在 CPython 中才有，而在 PyPy 和 Jython 中是没有 GIL 的。


### 创建多线程

Python中使用线程有两种方式：函数或者用类来包装线程对象。

* 直接使用函数式
* 继承threading.Thread来自定义线程类，重写run方法


### 线程模块
Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁。

函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下:
```python
thread.start_new_thread ( function, args[, kwargs] )
```
参数说明:

* function - 线程函数。
* args - 传递给线程函数的参数,他必须是个tuple类型。
* kwargs - 可选参数。


threading 模块提供的其他方法：

* threading.currentThread(): 返回当前的线程变量。
* threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。
* threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。

除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法:

* run(): 用以表示线程活动的方法。
* start():启动线程活动。
* join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。
* isAlive(): 返回线程是否活动的。
* getName(): 返回线程名。
* setName(): 设置线程名。


### 线程合并
Join函数执行顺序是逐个执行每个线程，执行完毕后继续往下执行。主线程结束后，子线程还在运行，join函数使得主线程等到子线程结束时才退出。


### 线程同步与互斥锁

使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。

RLock内部维护着一个Lock和一个counter变量，counter 记录了 acquire 的次数，从而使得资源可以被多次 require。直到一个线程所有的 acquire 都被 release，其他的线程才能获得资源。

用法的基本步骤：
```python
#创建锁
mutex = threading.Lock()
#锁定
mutex.acquire([timeout])
#释放
mutex.release()
```
其中，锁定方法acquire可以有一个超时时间的可选参数timeout。如果设定了timeout，则在超时后通过返回值可以判断是否得到了锁，从而可以进行一些其他的处理。

```python
#创建 RLock
mutex = threading.RLock() 
class MyThread(threading.Thread): 
    def run(self): 
        if mutex.acquire(1): 
            print("thread " + self.name + " get mutex") 
            time.sleep(1) 
            mutex.acquire() 
            mutex.release() 
            mutex.release()
```

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
import threading
import time
 
class myThread (threading.Thread):
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter
    def run(self):
        print "Starting " + self.name
       # 获得锁，成功获得锁定后返回True
       # 可选的timeout参数不填时将一直阻塞直到获得锁定
       # 否则超时后将返回False
        threadLock.acquire()
        print_time(self.name, self.counter, 3)
        # 释放锁
        threadLock.release()
 
def print_time(threadName, delay, counter):
    while counter:
        time.sleep(delay)
        print "%s: %s" % (threadName, time.ctime(time.time()))
        counter -= 1
 
threadLock = threading.Lock()
threads = []
 
# 创建新线程
thread1 = myThread(1, "Thread-1", 1)
thread2 = myThread(2, "Thread-2", 2)
 
# 开启新线程
thread1.start()
thread2.start()
 
# 添加线程到线程列表
threads.append(thread1)
threads.append(thread2)
 
# 等待所有线程完成
for t in threads:
    t.join()
print "Exiting Main Thread"
```


### 线程优先级队列（ Queue）
Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。

Queue模块中的常用方法:
* Queue.qsize() 返回队列的大小
* Queue.empty() 如果队列为空，返回True,反之False
* Queue.full() 如果队列满了，返回True,反之False
* Queue.full 与 maxsize 大小对应
* Queue.get([block[, timeout]])获取队列，timeout等待时间
* Queue.get_nowait() 相当Queue.get(False)
* Queue.put(item) 写入队列，timeout等待时间
* Queue.put_nowait(item) 相当Queue.put(item, False)
* Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号
* Queue.join() 实际上意味着等到队列为空，再执行别的操作

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
import Queue
import threading
import time
 
exitFlag = 0
 
class myThread (threading.Thread):
    def __init__(self, threadID, name, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.q = q
    def run(self):
        print "Starting " + self.name
        process_data(self.name, self.q)
        print "Exiting " + self.name
 
def process_data(threadName, q):
    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            data = q.get()
            queueLock.release()
            print "%s processing %s" % (threadName, data)
        else:
            queueLock.release()
        time.sleep(1)
 
threadList = ["Thread-1", "Thread-2", "Thread-3"]
nameList = ["One", "Two", "Three", "Four", "Five"]
queueLock = threading.Lock()
workQueue = Queue.Queue(10)
threads = []
threadID = 1
 
# 创建新线程
for tName in threadList:
    thread = myThread(threadID, tName, workQueue)
    thread.start()
    threads.append(thread)
    threadID += 1
 
# 填充队列
queueLock.acquire()
for word in nameList:
    workQueue.put(word)
queueLock.release()
 
# 等待队列清空
while not workQueue.empty():
    pass
 
# 通知线程是时候退出
exitFlag = 1
 
# 等待所有线程完成
for t in threads:
    t.join()
print "Exiting Main Thread"
```


###  守护线程

如果希望主线程执行完毕之后，不管子线程是否执行完毕都随着主线程一起结束。我们可以使用setDaemon(bool)函数，它跟join函数是相反的。它的作用是设置子线程是否随主线程一起结束，必须在start() 之前调用，默认为False。


### Timer(定时器)
Timer:  隔一定时间调用一个函数,如果想实现每隔一段时间就调用一个函数的话，就要在Timer调用的函数中，再次设置Timer。Timer是Thread的一个派生类

```python
import threading
import time

def hello(name):
    print "hello %s\n" % name

    global timer
    timer = threading.Timer(2.0, hello, ["Hawk"])
    timer.start()

if __name__ == "__main__":
    timer = threading.Timer(2.0, hello, ["Hawk"])
    timer.start()
```


## 多进程

### 创建多进程
Python 要进行多进程操作，需要用到muiltprocessing库，其中的Process类跟threading模块的Thread类很相似。所以直接看代码熟悉多进程。

1. 直接使用Process, 代码如下：
    ```python
    from multiprocessing import Process 

    def show(name): 
        print("Process name is " + name) 

    if __name__ == "__main__": 
        proc = Process(target=show, args=('subprocess',)) 
        proc.start() 
        proc.join()
    ```

2. 继承Process来自定义进程类，重写run方法, 代码如下：
    ```python
    from multiprocessing import Process 
    import time 
    
    class MyProcess(Process): 
        def __init__(self, name): 
            super(MyProcess, self).__init__() 
            self.name = name 

        def run(self): 
            print('process name :' + str(self.name)) 
            time.sleep(1) 

    if __name__ == '__main__': 
        for i in range(3): 
            p = MyProcess(i) 
            p.start() 
        for i in range(3):
            p.join()
    ```


### 多进程通信

进程之间不共享数据的。如果进程之间需要进行通信，则要用到Queue模块或者Pipi模块来实现。

Queue 是多进程安全的队列，可以实现多进程之间的数据传递。它主要有两个函数,put和get。
```python
from multiprocessing import Process, Queue 

def put(queue): 
    queue.put('Queue 用法') 

if __name__ == '__main__': 
    queue = Queue() 
    pro = Process(target=put, args=(queue,)) 
    pro.start() 
    print(queue.get()) 
    pro.join()
```

Pipe的本质是进程之间的用管道数据传递，而不是数据共享，这和socket有点像。pipe() 返回两个连接对象分别表示管道的两端，每端都有send() 和recv()函数。
```python
from multiprocessing import Process, Pipe 

def show(conn): 
    conn.send('Pipe 用法') 
    conn.close() 
    
if __name__ == '__main__': 
    parent_conn, child_conn = Pipe() 
    pro = Process(target=show, args=(child_conn,)) 
    pro.start() 
    print(parent_conn.recv()) 
    pro.join()
```


### 进程池

|方法 	    |含义
-----------|--------
|apply() 	|同步执行（串行）
|apply_async() 	|异步执行（并行）
|terminate() 	|立刻关闭进程池
|join() 	|主进程等待所有子进程执行完毕。必须在close或terminate()之后使用
|close() 	|等待所有进程结束后，才关闭进程池

```python
from multiprocessing import Pool 

def show(num): 
    print('num : ' + str(num)) 

    if __name__=="__main__": 
        pool = Pool(processes = 3)
        for i in xrange(6): 
            # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去 
            pool.apply_async(show, args=(i, )) 
        print('====== apply_async ======') 
        pool.close() 
        #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束 
        pool.join()
```


## 选择多线程还是多进程？

在这个问题上，首先要看下你的程序是属于哪种类型的。一般分为两种 CPU 密集型 和 I/O 密集型。

* CPU 密集型：程序比较偏重于计算，需要经常使用 CPU 来运算。例如科学计算的程序，机器学习的程序等。
* I/O 密集型：顾名思义就是程序需要频繁进行输入输出操作。爬虫程序就是典型的 I/O 密集型程序。

如果程序是属于 CPU 密集型，建议使用多进程。而多线程就更适合应用于 I/O 密集型程序。
